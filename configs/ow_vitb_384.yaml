_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "OWCATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "OWCATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255

    # ðŸ”§ NEW: Mode selection
    EVALUATION_MODE: "OVSS"  # "OVSS" or "OWSS"
    # OVSS Mode: Open-Vocabulary Semantic Segmentation
    # - 0~74: Known classes (text)
    # - 75~149: Unknown classes (text)
    # - Total: 150 classes

    # OWSS Mode: Open-World Semantic Segmentation
    # - 0~74: Known classes (text)
    # - 75~149 â†’ 150: Unknown classes (attributes)
    # - Total: 75 + 1 = 76 classes

    #NUM_CLASSES: 171
    NUM_CLASSES_TRAIN: 171
    NUM_CLASSES_TEST: 150

    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/ade150.json"

    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"

    #ow-ovss new
  #    EMBEDDING_PATH: "data/coco/cls_embeddings.npy"
  #    ATT_EMBEDDINGS: "data/coco/att_embeddings.pth"
    EMBEDDING_PATH: "data/coco/cls_embeddings.npy"
    ATT_EMBEDDINGS: "data/coco/att_embeddings.pth"

    PREV_INTRO_CLS: 0    # PREVIOUS TEST TASK'S CLASS NUM
    CUR_INTRO_CLS: 75    # CURRENT TEST TASK'S CLASS NUM
    UNKNOWN_ID: 150      # TEST DATASET'S UNKNOWN ID (EQUAL TO TEST DATASET'S NUM)
    THR: 0.75           # Threshold for attribute prediction
    ALPHA: 0.3          # Alpha for attribute selection
    USE_SIGMOID: True
    PREV_DISTRIBUTION: None
    DISTRIBUTIONS: "data/coco/distributions.pth"
    TOP_K: 10           # Top-k attributes for unknown prediction
    FUSION_ATT: False

    # NEW: OW Evaluation mode
    ENABLE_OW_MODE: True        # Set to False for baseline comparison

  PROMPT_ENSEMBLE_TYPE: "single"


# í•™ìŠµê³¼ í‰ê°€ ë°ì´í„°ì…‹ ë¶„ë¦¬
DATASETS:
  TRAIN: ("coco_2017_train_stuff_all_sem_seg",)  # COCO-STUFFë¡œ í•™ìŠµ
  TEST: ("ade20k_150_ow_val_sem_seg",)           # ADE20K-150ìœ¼ë¡œ í‰ê°€

INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "ow_mask_former_semantic"

SOLVER:
  IMS_PER_BATCH: 1 # 4->2
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 10000 #80000->100
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01

TEST:
  EVAL_PERIOD: 0 #5000->100

ATTRIBUTE_LOG_START_ITER: 0
ATTRIBUTE_SELECT_ITER: 5000